{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get Packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'colormaps'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph_objects\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mgo\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moffline\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m init_notebook_mode, iplot, plot\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcolormaps\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mcmaps\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolors\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmc\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'colormaps'"
     ]
    }
   ],
   "source": [
    "# include matplotlib widget\n",
    "%matplotlib widget\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from plotly.offline import init_notebook_mode, iplot, plot\n",
    "import colormaps as cmaps\n",
    "import seaborn as sns\n",
    "import matplotlib.colors as mc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Run this line if you are in a Jupyter Notebook environment\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "# define paths for data and output\n",
    "paths = {\"base\": \"C://Users//avonl//OneDrive//Work//Research//projects//2023 - FRESH//code//FRESH//\", \n",
    "         \"alex\": \"alex//\", \n",
    "         \"data\": \"data//\", \n",
    "         \"tempfigs\": \"figs\",\n",
    "         \"finalfigs\": \"figures//\" \n",
    "        }\n",
    "\n",
    "# set colormap name\n",
    "colormap_name = \"tofino\"\n",
    "# get color map\n",
    "cmap = getattr(cmaps, colormap_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**load CSV file and clean data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loads csv to pandas dataframe\n",
    "df = pd.read_csv(paths[\"base\"]+paths[\"data\"]+\"FreshData.csv\", encoding='utf-16', delimiter='\\t')\n",
    "\n",
    "# unifies NaNs: Replace all \"NaN\" values in df with \"nan\"\n",
    "df = df.replace(np.nan, 'nan', regex=True)\n",
    "\n",
    "# specific for this analysis: replace all \"NaN\"s in df with \"Unknown\"\n",
    "df = df.replace('nan', 'Unknown', regex=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Select and Prepare Data for Signal Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selection of columns to keep for signal analysis\n",
    "columns_sig = ['Study', 'ID', 'Toolbox used', \\\n",
    "           'Quality/Pruning: Method','Motion Artifact Method', \\\n",
    "           'Resample/Downsample (Hz)','Filtering Coding', \\\n",
    "           'Removal of the Global Signals during Preprocessing', \\\n",
    "           'Non-GLM: Method', 'GLM: Method', 'GLM: HRF Regressor', \\\n",
    "           'GLM: Other Regressors', 'Block Averaging: Modifiers']\n",
    "df_siganalysis = df[columns_sig]\n",
    "\n",
    "# rename 'Non-GLM Method' to 'Approach'\n",
    "df_siganalysis = df_siganalysis.rename(columns={'Non-GLM: Method': 'Approach'})\n",
    "\n",
    "# remove lines that contain \"Not investigated\" in column \"Toolbox used\"\n",
    "df_siganalysis = df_siganalysis[~df_siganalysis['Toolbox used'].str.contains('Not investigated')]\n",
    "\n",
    "# Removes \"Custom: \" substring from the entries in column \"Toolbox used\" of df_analysis and keeps only the rest.\n",
    "df_siganalysis['Toolbox used'] = df_siganalysis['Toolbox used'].str.replace('Custom:', '')\n",
    "df_siganalysis['Toolbox used'] = df_siganalysis['Toolbox used'].str.replace('Custom: ', '')\n",
    "\n",
    "column_none = ['Quality/Pruning: Method', 'Motion Artifact Method', \\\n",
    "    'Resample/Downsample (Hz)', 'Filtering Coding']\n",
    "none_txt = ['No Pruning', 'No Artifact Removal', 'No Resampling', 'No Filtering']\n",
    "# rename entries in columns indicated in column_none that contain an \"Unknown\" to the corresponding entry in none_txt\n",
    "for i in range(len(column_none)):\n",
    "    df_siganalysis[column_none[i]] = df_siganalysis[column_none[i]].replace('Unknown', none_txt[i], regex=True)\n",
    "\n",
    "    \n",
    "# rename \"Other\" entries in column 'Quality/Pruning: Method' to 'Other Pruning Method'\n",
    "df_siganalysis['Quality/Pruning: Method'] = df_siganalysis['Quality/Pruning: Method'].replace('Other', 'Other Pruning Method', regex=True)\n",
    "# In \"Quality/Pruning: Method\" rename \"Manual Selection\" and \"Visual Inspection of Time Domain\" to \"Manual Pruning\"\n",
    "df_siganalysis['Quality/Pruning: Method'] = df_siganalysis['Quality/Pruning: Method'].replace('Manual Selection', 'Manual Pruning', regex=True)\n",
    "df_siganalysis['Quality/Pruning: Method'] = df_siganalysis['Quality/Pruning: Method'].replace('Visual Inspection of Time Domain', 'Manual Pruning', regex=True)\n",
    "\n",
    "# rename \"Other\" entries in column 'Motion Artifact Method' to 'Other Removal Method'\n",
    "df_siganalysis['Motion Artifact Method'] = df_siganalysis['Motion Artifact Method'].replace('Other', 'Other Removal Method', regex=True)\n",
    "# rename \"Rejection\" entries in column 'Motion Artifact Method' to 'Trial Rejection'\n",
    "df_siganalysis['Motion Artifact Method'] = df_siganalysis['Motion Artifact Method'].replace('Rejection', 'Trial Rejection', regex=True)\n",
    "\n",
    "# rename \"Unknown\"\" entries in column 'Removal of the Global Signals during Preprocessing' to 'No Removal''\n",
    "df_siganalysis['Removal of the Global Signals during Preprocessing'] = df_siganalysis['Removal of the Global Signals during Preprocessing'].replace('No', 'No Removal', regex=True)\n",
    "# rename \"No\" entries in column 'Removal of the Global Signals during Preprocessing' to 'No Removal''\n",
    "df_siganalysis['Removal of the Global Signals during Preprocessing'] = df_siganalysis['Removal of the Global Signals during Preprocessing'].replace('Unknown', 'No Removal', regex=True)\n",
    "# rename \"Other\" entries in column 'Removal of the Global Signals during Preprocessing' to 'Other Removal''\n",
    "df_siganalysis['Removal of the Global Signals during Preprocessing'] = df_siganalysis['Removal of the Global Signals during Preprocessing'].replace('Other', 'Other Method', regex=True)\n",
    "\n",
    "# rename \"Unknown\" entries in column 'GLM: Method' to 'Unknown Method'\n",
    "df_siganalysis['GLM: Method'] = df_siganalysis['GLM: Method'].replace('Unknown', 'Unknown Method', regex=True)\n",
    "# rename \"Default\" entries in column 'GLM: Method' to 'Default Method'\n",
    "df_siganalysis['GLM: Method'] = df_siganalysis['GLM: Method'].replace('Default', 'Default Method', regex=True)\n",
    "# replace any entry in column \"GLM: Method\" that contains the string \"AR-IRLS\" completely with only \"AR-IRLS\"\n",
    "df_siganalysis['GLM: Method'] = df_siganalysis['GLM: Method'].replace('AR-IRLS.*', 'AR-IRLS', regex=True)\n",
    "# rename \"Other\" entries in column 'GLM: Method' to 'Other Method'\n",
    "df_siganalysis['GLM: Method'] = df_siganalysis['GLM: Method'].replace('Other', 'Other Solver', regex=True)\n",
    "\n",
    "\n",
    "# rename \"Unknown\" entries in column 'GLM: HRF Regressor' to 'Unknown HRF Regressor'\n",
    "df_siganalysis['GLM: HRF Regressor'] = df_siganalysis['GLM: HRF Regressor'].replace('Unknown', 'Unknown HRF Regressor', regex=True)\n",
    "# rename \"Default\" entries in column 'GLM: HRF Regressor' to 'Default HRF Regressor'\n",
    "df_siganalysis['GLM: HRF Regressor'] = df_siganalysis['GLM: HRF Regressor'].replace('Default', 'Default HRF Regressor', regex=True)\n",
    "\n",
    "# rename \"Unknown\" entries and \"Other\" entries in column 'GLM: Other Regressors' to 'Unknown Other Regressors'\n",
    "df_siganalysis['GLM: Other Regressors'] = df_siganalysis['GLM: Other Regressors'].replace('Unknown', 'Unknown Additional Regressors', regex=True)\n",
    "df_siganalysis['GLM: Other Regressors'] = df_siganalysis['GLM: Other Regressors'].replace('Other', 'Unknown Additional Regressors', regex=True)\n",
    "\n",
    "\n",
    "# for all rows that contain \"Block Averaging\" or \"Other\" in column \"Approach\"... \n",
    "rw_idx = df_siganalysis.loc[df_siganalysis['Approach'].str.contains('Block Averaging')].index\n",
    "rw_idx = rw_idx.append(df_siganalysis.loc[df_siganalysis['Approach'].str.contains('Other')].index)\n",
    "#...\n",
    "#...\n",
    "# replace the the cell in column \"GLM: Method\" with the corresponding cell from \"Block Averaging: Modifiers\" for these rows\n",
    "df_siganalysis.loc[rw_idx, 'GLM: Method'] = df_siganalysis.loc[rw_idx, 'Block Averaging: Modifiers']\n",
    "# for these rows, replace \"Unknown\" with \"No Correction\"\n",
    "df_siganalysis.loc[rw_idx, 'GLM: Method'] = df_siganalysis.loc[rw_idx, 'GLM: Method'].replace('Unknown', 'No Correction', regex=True)\n",
    "\n",
    "# ...replace \"Unknown HRF Regressor\" in column \"GLM: HRF Regressor\" with an empty string\n",
    "df_siganalysis.loc[rw_idx, 'GLM: HRF Regressor'] = df_siganalysis.loc[rw_idx, 'GLM: HRF Regressor'].replace('Unknown HRF Regressor', '', regex=True)\n",
    "# ...replace \"Unknown Other Regressor\" in column \"GLM: Other Regressors\" with an empty string\n",
    "df_siganalysis.loc[rw_idx, 'GLM: Other Regressors'] = df_siganalysis.loc[rw_idx, 'GLM: Other Regressors'].replace('Unknown Additional Regressors', '', regex=True)\n",
    "\n",
    "# delete column \"Block Averaging: Modifiers\"\n",
    "df_siganalysis = df_siganalysis.drop(columns=['Block Averaging: Modifiers'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot Toolbox Statistics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create distinct entries (rows) for each item in a list of items separated by commas\n",
    "df_sig_tb = df_siganalysis['Toolbox used']\n",
    "numentries = len(df_sig_tb)\n",
    "df_sig_tb = df_sig_tb.apply(lambda x: x.split(','))\n",
    "df_sig_tb = df_sig_tb.explode('Toolbox used')\n",
    "# removes empty entries\n",
    "df_sig_tb = df_sig_tb[df_sig_tb != '']\n",
    "# removes all spaces from the beginning and end of each entry\n",
    "df_sig_tb = df_sig_tb.str.strip()\n",
    "\n",
    "# Calculate relative frequencies\n",
    "df_pipe_tb_counts = pd.Series(df_sig_tb).value_counts(normalize=False)/numentries*100\n",
    "# Create custom text for each slice\n",
    "custom_text_pipe_tb = [f'{label}<br>{value:.2f}%' for label, value in zip(df_pipe_tb_counts.index, df_pipe_tb_counts)]\n",
    "\n",
    "# extract and assign colors from colormap\n",
    "num_categories=len(df_pipe_tb_counts)\n",
    "# Sample colors from the colormap\n",
    "#colors = cmap(np.linspace(0, 1, num_categories))\n",
    "colors = cmap.discrete(num_categories)\n",
    "# Convert colors to hex format\n",
    "plotly_colors = ['#' + ''.join([f'{int(c * 255):02x}' for c in colors(i)[:3]]) for i in range(num_categories)]\n",
    "\n",
    "# Create the pie chart\n",
    "fig = go.Figure(data=go.Pie(\n",
    "    labels=df_pipe_tb_counts.index,\n",
    "    values=df_pipe_tb_counts.values,\n",
    "    text = custom_text_pipe_tb,\n",
    "    textposition='auto',\n",
    "    textinfo = 'text',\n",
    "    textfont=dict(size=16),\n",
    "    marker=dict(colors=plotly_colors)\n",
    "))\n",
    "\n",
    "\n",
    "\n",
    "# Set the layout\n",
    "fig.update_layout(\n",
    "    title='Use of Tools and Toolboxes for Analysis',\n",
    "    showlegend=False\n",
    ")\n",
    "\n",
    "# Show the chart\n",
    "fig.show()\n",
    "# Save the chart\n",
    "plot(fig, filename='figs/pie_AnalysisToolboxes.html')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prepare Data and Nodes for Analysis Sankey Diagram**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# create distinct entries (rows) for each item in a list of items separated by commas (e.g. for different Toolboxes)\n",
    "column_list = ['Quality/Pruning: Method', 'Motion Artifact Method', 'Resample/Downsample (Hz)', \\\n",
    "    'Filtering Coding', 'Removal of the Global Signals during Preprocessing', 'Approach', \\\n",
    "        'GLM: Method', 'GLM: HRF Regressor', 'GLM: Other Regressors']\n",
    "\n",
    "# save number of entries in df_siganalysis\n",
    "numentries_sa = len(df_siganalysis)\n",
    "# save copy of df_siganalysis\n",
    "df_siganalysis_notexp = df_siganalysis.copy()\n",
    "\n",
    "# split entries and save relative weights in corresponding new columns\n",
    "\"\"\" for columnName in column_list:\n",
    "    df_siganalysis['weight '+columnName] = df_siganalysis[columnName].apply(lambda x: 1 / len(x.split(',')) if x else 1)\n",
    "    df_siganalysis[columnName] = df_siganalysis[columnName].apply(lambda x: x.split(','))\n",
    "    df_siganalysis = df_siganalysis.explode(columnName) \"\"\"\n",
    "\n",
    "# copy 'ID' and  all data from columns of df_siganalyis that contain 'weight ' to a new pandas data frame 'weights_siganalysis'\n",
    "weights_siganalysis = df_siganalysis[['ID']]\n",
    "for columnName in df_siganalysis.columns:\n",
    "    if 'weight ' in columnName:\n",
    "        weights_siganalysis[columnName] = df_siganalysis[columnName]\n",
    "#remove 'weight ' from column names\n",
    "weights_siganalysis.columns = weights_siganalysis.columns.str.replace('weight ', '')\n",
    "# remove all columns of df_siganalysis that contain 'weight '\n",
    "df_siganalysis = df_siganalysis.loc[:, ~df_siganalysis.columns.str.contains('weight ')]\n",
    "\n",
    "\n",
    "\n",
    "# Create a list of all nodes (i.e., unique values in the listed columns in column_list)\n",
    "nodes = pd.concat([df_siganalysis[col] for col in column_list]).unique()\n",
    "\n",
    "# Create a dictionary that maps each node to a unique index\n",
    "node_indices = {node: i for i, node in enumerate(nodes)}\n",
    "\n",
    "# Create lists to store the source, target, and value for each link\n",
    "source, target, value = [], [], []\n",
    "\n",
    "for i, row in df_siganalysis.iterrows():\n",
    "    for j in range(len(column_list) - 1):\n",
    "        current_col = column_list[j]\n",
    "        next_col = column_list[j + 1]\n",
    "        # Check if current_col or next_col is an empty string\n",
    "        if row[current_col] == '' or row[next_col] == '':\n",
    "            break\n",
    "\n",
    "        source.append(node_indices[row[current_col]])\n",
    "        target.append(node_indices[row[next_col]])\n",
    "        value.append(1)\n",
    "\n",
    "\n",
    "# Generate distinct colors from the seaborn spectral color palette\n",
    "num_colors = len(nodes)\n",
    "palette = cmap(np.linspace(0, 1, num_colors))\n",
    "# Define colors for each node\n",
    "node_colors_hex = [mc.to_hex(color) for color in palette]\n",
    "\n",
    "# Function to convert hex color to RGBA with specified transparency\n",
    "def hex_to_rgba(hex_color, alpha=0.5):\n",
    "    # Convert hex to an RGB tuple\n",
    "    rgb_tuple = mc.to_rgb(hex_color)\n",
    "    # Convert the RGB tuple to an RGBA string with the specified alpha value\n",
    "    return \"rgba({r},{g},{b}, {alpha})\".format(r=int(rgb_tuple[0]*255), g=int(rgb_tuple[1]*255), b=int(rgb_tuple[2]*255), alpha=alpha)\n",
    "\n",
    "# initialize link_colors with length of source with empty strings\n",
    "link_colors = [''] * len(source)\n",
    "node_colors = [''] * len(nodes)\n",
    "\n",
    "# Generate link and node colors \n",
    "for i in range(len(nodes)):\n",
    "    # node colors in rgba and not transparent\n",
    "    node_colors[i] = hex_to_rgba(node_colors_hex[i], alpha=1)\n",
    "for s in source:\n",
    "    # link colors based on the color of their source node with 0.5 transparency\n",
    "    link_colors[s] = hex_to_rgba(node_colors_hex[source[s]], alpha=0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculate Statistics/Frequencies of Entries in Analysis**\n",
    "\n",
    "Count the times that methods/steps were performed and report the relative frequencies in percent (sometimes several steps from the same stage are performed. to correct for this use the weights in weights_signalanalysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the occurence of all items from the list of nodes in df_signalanalysis and save it in a dictionary\n",
    "abs_node_count = {}\n",
    "\n",
    "# Calculate relative frequencies\n",
    "df_pipe_tb_counts = pd.Series(df_sig_tb).value_counts(normalize=False)/numentries_sa*100\n",
    "\n",
    "for node in nodes:\n",
    "\n",
    "# find columns and row indices of values that contain the node\n",
    "    col_name = [col for col in column_list if node in df_siganalysis[col].unique()]\n",
    "    # Find rows where 'node' is present\n",
    "    mask = df_siganalysis.apply(lambda x: node in x.values, axis=1)\n",
    "    # Get the indices of rows where 'node' is found\n",
    "    row_indices = mask[mask].index.tolist()\n",
    "    # calculate the sum of the weights of the rows where 'node' is found\n",
    "    abs_node_count[node] = weights_siganalysis.loc[row_indices, col_name].sum(axis=0)[0]\n",
    "\n",
    "\n",
    "    #abs_node_count[node] = df_siganalysis.apply(lambda x: node in x.values, axis=1).sum()\n",
    "\n",
    "print(abs_node_count)\n",
    "\n",
    "\n",
    "# calculate relative node count in % by normalizing with the total number of rows in df_signalanalysis\n",
    "rel_node_count = {key: (abs_node_count[key] / numentries_sa)*100 for key in abs_node_count.keys()}\n",
    "# round the relative node count to 1 decimal\n",
    "rel_node_count = {key: round(rel_node_count[key], 1) for key in rel_node_count.keys()}    \n",
    "\n",
    "# Make the label list for the nodes, adding the relative node count in % to the node name\n",
    "node_labels = [node + ' (' + str(rel_node_count[node]) + '%)' for node in nodes]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot Analysis Sankey Diagram**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(data=[go.Sankey(\n",
    "    node=dict(\n",
    "        pad=15,\n",
    "        thickness=20,\n",
    "        line=dict(color='black', width=0.5),\n",
    "        label=node_labels,\n",
    "        color= node_colors  # Assign the colors to the nodes\n",
    "    ),\n",
    "    link=dict(\n",
    "        source=source,\n",
    "        target=target,\n",
    "        value=value,\n",
    "        #color= link_colors  # Assign the colors to the links\n",
    "    )\n",
    ")])\n",
    "\n",
    "fig.update_layout(\n",
    "    autosize=True,\n",
    ")\n",
    "\n",
    "## Rename column labels\n",
    "column_labels = column_list\n",
    "# remove \":\" from elements in column_labels\n",
    "column_labels = [x.replace(':', '') for x in column_labels]\n",
    "# rename \"Approach\" to \"Solver / Modifiers\"\n",
    "column_labels = [x.replace('Approach', 'HRF Estimation') for x in column_labels]\n",
    "# rename \"GLM Method\" to \"Solver / Modifiers\"\n",
    "column_labels = [x.replace('GLM Method', 'Solver / Modifiers') for x in column_labels]\n",
    "# rename \"Removal of the Global Signals during Preprocessing\" to \"Physiology Preprocessing\"\n",
    "column_labels = [x.replace('Removal of the Global Signals during Preprocessing', 'Physiology Preprocessing') for x in column_labels]\n",
    "# rename \"Resample/Downsample (Hz)\" to \"Resampling (Hz)\"\n",
    "column_labels = [x.replace('Resample/Downsample (Hz)', 'Resampling (Hz)') for x in column_labels]\n",
    "# rename \"Filtering Coding\" to \"Filtering\"\n",
    "column_labels = [x.replace('Filtering Coding', 'Filtering') for x in column_labels]\n",
    "\n",
    "# Calculate the x position for each column's label.\n",
    "# This is a rough approximation and may need to be adjusted based on the exact look of your Sankey diagram.\n",
    "x_positions = [i / (len(column_labels) - 1) for i in range(len(column_labels))]\n",
    "\n",
    "annotations = [\n",
    "    dict(\n",
    "        x=x,\n",
    "        y=1.05,  # Adjust the y-coordinate as per desired placement\n",
    "        xref='paper',\n",
    "        yref='paper',\n",
    "        text=label,\n",
    "        showarrow=False,\n",
    "        font=dict(size=16)\n",
    "    ) for x, label in zip(x_positions, column_labels)\n",
    "]\n",
    "\n",
    "# Update the layout with annotations\n",
    "fig.update_layout(\n",
    "    annotations=annotations,\n",
    "    autosize=True,\n",
    "    font=dict(size=16),  # Set global font size\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "plot(fig, filename='figs/sankey_analysispipeline.html')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
